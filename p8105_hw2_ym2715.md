P8105\_hw2\_ym2715
================
Yizhi Ma
10/5/2018

Problem 1
---------

``` r
subway_df = read.csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names()

subway_tidy_df = subway_df %>% 
  select(line, station_name, station_latitude, station_longitude, entry, vending, entrance_type, ada, route1, route2, route3, route4, route5, route6, route7, route8, route9, route10, route11) %>% 
  distinct() %>% 
  mutate(entry = if_else(entry == "YES", TRUE, FALSE)) # Convert the entry variable from character to a logical variable
```

So far, I've used "janitor::clean\_names" to keep the names consistent among variables. Then I select the variables that I need and use "distinct" to remove rows that are exactly the same.

The current data set -- subway\_tidy\_df -- contains some information about NYC subway system, including lines, different stations on each line with their location expressed in latitude and longitude. It tells us whether the entry is avaliable, which entrence type it is, if there's vending and ADA compliant, and also, which train stops at the stations.

The dataset is now a 684 x 19 table. I name it with "tidy" but I don't think it's tidy enough, the route part seems a little bit annoying.

``` r
subway_tidy_df %>% 
  distinct(line, station_name) %>% 
  nrow()
```

    ## [1] 465

There're 465 subway stations in NYC.

``` r
subway_tidy_df %>% 
  distinct(line, station_name, ada) %>% 
  count(ada)
```

    ## # A tibble: 2 x 2
    ##   ada       n
    ##   <lgl> <int>
    ## 1 FALSE   381
    ## 2 TRUE     84

There're 84 stations that area ADA compliant.

``` r
x = subway_df %>% 
      filter(entry == 'YES' & vending == 'NO') %>% 
      nrow()
proportion = x / nrow(subway_df)
proportion
```

    ## [1] 0.0369379

The proportion of station entrances / exits without vending allow entrance is 0.0369379

Problem 2
---------

Read and Clean Mr. Trash Wheel dataset

``` r
trashwheel_df = readxl::read_xlsx("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "Mr. Trash Wheel", range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  na.omit(dumpster) %>%
  mutate(sports_balls = as.integer(round(sports_balls)))
```

Read and clean precipitation data for 2016 and 2017

``` r
prec_2016_df = readxl::read_xlsx("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "2016 Precipitation", range = "A2:B14") %>% 
  janitor::clean_names() %>% 
  mutate(year = 2016) %>% 
  select(year, everything())

prec_2017_df = readxl::read_xlsx("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "2017 Precipitation", range = "A2:B14") %>% 
  janitor::clean_names() %>% 
  mutate(year = 2017) %>% 
  select(year, everything())
```

Combine the 2016 & 2017 datasets

``` r
prec_df = bind_rows(prec_2016_df, prec_2017_df) %>% 
  mutate(month = month.name[month])
```

the total precipitation in 2017 is 32.93

``` r
  sum(prec_2017_df$total)
```

    ## [1] 32.93

the median number of sports balls in a dumpster in 2016 is 26

``` r
median(filter(trashwheel_df, year == 2016) $ sports_balls)
```

    ## [1] 26

Problem 3
---------

Load BRFSS data and do some data cleaning as required

``` r
library(p8105.datasets)

brfss_smart2010 = p8105.datasets::brfss_smart2010

brfss_overall_health = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  select(-class, -topic, -question, -sample_size, - (confidence_limit_low:geo_location)) %>% 
  spread(key = response, value = data_value) %>% 
  janitor::clean_names() %>% 
  mutate(excellent_or_very_good = excellent + very_good) %>% 
  select(year, location_abbr = locationabbr, location_desc = locationdesc, excellent_or_very_good, excellent, very_good, good, fair, poor)
```
